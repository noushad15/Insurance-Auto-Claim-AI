# Auto Claim AI System

An intelligent system for automated insurance claim processing using OCR, NLP, machine learning, and large language models (LLMs) â€” now with agentic (LangChain) AI workflows.

## ğŸ¥ Overview

The Auto Claim AI system processes insurance claim documents (PDFs and images) to:

1.  **Upload Claim File** - Accept PDF/Image uploads via a FastAPI endpoint.
2.  **OCR & NLP Parsing** - Extract text and structured data from documents.
3.  **Field Extraction** - Identify key claim information like patient name, diagnosis, and claimed amount.
4.  **AI Classification** - Determine the claim's approval status with confidence scores.
5.  **LLM & Agentic Workflows** - Use Azure OpenAI and LangChain agents for natural language explanations, Q&A, and step-by-step claim reasoning.
6.  **Database Storage** - Store claim data and processing results in a local database.

## ğŸš€ Features

- **Multi-format Support**: PDF and image file processing.
- **Advanced OCR**: Text extraction with image preprocessing.
- **NLP Field Extraction**: Intelligent field identification.
- **AI Classification**: Rule-based and ML-powered claim assessment.
- **LLM-Powered Workflows**: Natural language claim review and analytics.
- **Agentic Claim Processing**: Step-by-step, tool-using agent (LangChain) for robust, explainable claim decisions.
- **FastAPI Backend**: A robust backend to handle requests and serve the AI models.
- **Database Integration**: Store and retrieve claim information.

## ğŸ“ Project Structure

```
auto_claim_ai/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agentic_claim_agent.py    # Agentic claim processing logic
â”‚   â”œâ”€â”€ app.py                    # FastAPI application
â”‚   â”œâ”€â”€ classifier.py             # AI classification model
â”‚   â”œâ”€â”€ database.py               # Database models and sessions
â”‚   â”œâ”€â”€ field_extractor.py        # NLP field extraction
â”‚   â”œâ”€â”€ llm_utils.py              # Utilities for LLM interactions
â”‚   â””â”€â”€ ocr_parser.py             # OCR and text extraction
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_claims.pdf         # Sample claim documents
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ claim_classifier.pkl      # Trained classification model
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ claim_model_training.ipynb # Notebook for model training
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ populate_sample_data.py   # Script to populate the database
â”‚
â”œâ”€â”€ test/
â”‚   â””â”€â”€ ...                       # Test files
â”‚
â”œâ”€â”€ agent_test.py                 # Script for testing the agent
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- Tesseract OCR engine

### Setup Instructions

1.  **Clone the repository**
    ```bash
    git clone <repository-url>
    cd auto_claim_ai
    ```

2.  **Install Tesseract OCR**

    **macOS:**
    ```bash
    brew install tesseract
    ```

    **Ubuntu/Debian:**
    ```bash
    sudo apt-get install tesseract-ocr
    ```

    **Windows:**
    Download from [GitHub releases](https://github.com/UB-Mannheim/tesseract/wiki)

3.  **Install Python dependencies**
    ```bash
    pip install -r requirements.txt
    ```

## ğŸš€ Usage

### Running the Application

1.  **Start the FastAPI app**
    ```bash
    cd app
    uvicorn app:app --reload
    ```
    The application will be available at `http://127.0.0.1:8000`.

### Running the Agentic Claim Agent

You can test the agentic claim processing by running the `agent_test.py` script:

```bash
python agent_test.py
```

This script will simulate a claim processing request and show the agent's step-by-step reasoning.

## ğŸ“ API Endpoints

The following are the main endpoints available:

- `POST /upload/`: Upload a claim document (PDF or image) for processing.
- `GET /claims/`: Retrieve a list of all claims.
- `GET /claims/{claim_id}`: Retrieve the details of a specific claim.

For more details, you can access the auto-generated API documentation at `http://127.0.0.1:8000/docs`.
