{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Claim AI - Model Training Notebook\\n",
    "\\n",
    "This notebook demonstrates how to train and evaluate the claim classification model for the Auto Claim AI system.\\n",
    "\\n",
    "## Overview\\n",
    "- Generate synthetic training data\\n",
    "- Train the classification model\\n",
    "- Evaluate model performance\\n",
    "- Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\\n",
    "import os\\n",
    "sys.path.append('../app')\\n",
    "\\n",
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "from sklearn.model_selection import train_test_split\\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "from datetime import datetime, timedelta\\n",
    "import random\\n",
    "\\n",
    "from classifier import ClaimClassifier\\n",
    "from field_extractor import FieldExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_claims(n_samples=1000):\\n",
    "    \\"\\"\\"Generate synthetic claim data for training\\"\\"\\"\\n",
    "    \\n",
    "    # Sample data for different fields\\n",
    "    first_names = ['John', 'Jane', 'Bob', 'Alice', 'Charlie', 'Diana', 'Edward', 'Fiona', 'George', 'Helen']\\n",
    "    last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis', 'Rodriguez', 'Martinez']\\n",
    "    \\n",
    "    diagnoses = [\\n",
    "        'Fractured arm', 'Broken leg', 'Sprained ankle', 'Concussion', 'Chest pain',\\n",
    "        'Appendicitis', 'Heart attack', 'Stroke', 'Diabetes management', 'Hypertension',\\n",
    "        'Routine checkup', 'Flu shot', 'Dental cleaning', 'Eye exam', 'Physical therapy'\\n",
    "    ]\\n",
    "    \\n",
    "    providers = [\\n",
    "        'Dr. Smith', 'Dr. Johnson', 'Dr. Williams', 'Dr. Brown', 'Dr. Davis',\\n",
    "        'City Hospital', 'Medical Center', 'Urgent Care', 'Specialty Clinic'\\n",
    "    ]\\n",
    "    \\n",
    "    claims = []\\n",
    "    \\n",
    "    for i in range(n_samples):\\n",
    "        # Generate random claim data\\n",
    "        name = f\\"{random.choice(first_names)} {random.choice(last_names)}\\"\\n",
    "        \\n",
    "        # Generate date within last 2 years\\n",
    "        days_ago = random.randint(0, 730)\\n",
    "        date = (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m-%d')\\n",
    "        \\n",
    "        diagnosis = random.choice(diagnoses)\\n",
    "        provider = random.choice(providers)\\n",
    "        \\n",
    "        # Generate amount based on diagnosis\\n",
    "        if 'routine' in diagnosis.lower() or 'checkup' in diagnosis.lower():\\n",
    "            amount = random.uniform(50, 300)\\n",
    "        elif 'fracture' in diagnosis.lower() or 'broken' in diagnosis.lower():\\n",
    "            amount = random.uniform(2000, 8000)\\n",
    "        elif 'surgery' in diagnosis.lower() or 'appendicitis' in diagnosis.lower():\\n",
    "            amount = random.uniform(5000, 15000)\\n",
    "        else:\\n",
    "            amount = random.uniform(500, 3000)\\n",
    "        \\n",
    "        # Generate policy number\\n",
    "        policy_number = f\\"POL-{random.randint(10000, 99999)}\\"\\n",
    "        \\n",
    "        claim = {\\n",
    "            'name': name,\\n",
    "            'date': date,\\n",
    "            'diagnosis': diagnosis,\\n",
    "            'amount': f\\"{amount:.2f}\\",\\n",
    "            'provider': provider,\\n",
    "            'policy_number': policy_number,\\n",
    "            'service_date': date\\n",
    "        }\\n",
    "        \\n",
    "        claims.append(claim)\\n",
    "    \\n",
    "    return claims\\n",
    "\\n",
    "# Generate training data\\n",
    "print(\\"Generating synthetic training data...\\")\\n",
    "training_claims = generate_synthetic_claims(1000)\\n",
    "print(f\\"Generated {len(training_claims)} synthetic claims\\")\\n",
    "\\n",
    "# Convert to DataFrame\\n",
    "df = pd.DataFrame(training_claims)\\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Training Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier to extract features\\n",
    "classifier = ClaimClassifier()\\n",
    "\\n",
    "# Extract features for each claim\\n",
    "print(\\"Extracting features...\\")\\n",
    "features_list = []\\n",
    "labels = []\\n",
    "\\n",
    "for claim in training_claims:\\n",
    "    # Extract features\\n",
    "    features = classifier.extract_features(claim)\\n",
    "    features_list.append(features)\\n",
    "    \\n",
    "    # Generate label based on amount and diagnosis\\n",
    "    amount = float(claim['amount'])\\n",
    "    diagnosis = claim['diagnosis'].lower()\\n",
    "    \\n",
    "    # Simple rule for labeling\\n",
    "    if amount < 2000 and ('routine' not in diagnosis and 'checkup' not in diagnosis):\\n",
    "        label = 'approve'\\n",
    "    elif amount < 5000 and ('fracture' in diagnosis or 'broken' in diagnosis):\\n",
    "        label = 'approve'\\n",
    "    else:\\n",
    "        label = 'review'\\n",
    "    \\n",
    "    labels.append(label)\\n",
    "\\n",
    "print(f\\"Extracted features for {len(features_list)} claims\\")\\n",
    "print(f\\"Label distribution: {pd.Series(labels).value_counts().to_dict()}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\n",
    "    features_list, labels, test_size=0.2, random_state=42, stratify=labels\\n",
    ")\\n",
    "\\n",
    "print(f\\"Training set size: {len(X_train)}\\")\\n",
    "print(f\\"Testing set size: {len(X_test)}\\")\\n",
    "\\n",
    "# Train the model\\n",
    "print(\\"Training model...\\")\\n",
    "accuracy = classifier.train_model(X_train, y_train, save_path='../models/claim_classifier.pkl')\\n",
    "\\n",
    "print(f\\"Model training completed with accuracy: {accuracy:.3f}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\\n",
    "print(\\"Evaluating model performance...\\")\\n",
    "\\n",
    "# Make predictions on test set\\n",
    "test_predictions = []\\n",
    "test_probabilities = []\\n",
    "\\n",
    "for features in X_test:\\n",
    "    # Create a dummy extracted_fields dict for classification\\n",
    "    extracted_fields = {\\n",
    "        'amount': str(features.get('amount', 0)),\\n",
    "        'diagnosis': 'test diagnosis',\\n",
    "        'name': 'Test Name' if features.get('has_name') else '',\\n",
    "        'date': '2024-01-01' if features.get('has_date') else ''\\n",
    "    }\\n",
    "    \\n",
    "    result = classifier.classify_claim(extracted_fields)\\n",
    "    prediction = result['prediction']\\n",
    "    confidence = result['confidence'] / 100.0  # Convert to 0-1 scale\\n",
    "    \\n",
    "    # Convert to binary labels for evaluation\\n",
    "    pred_label = 'approve' if prediction == 'Auto-Approve' else 'review'\\n",
    "    test_predictions.append(pred_label)\\n",
    "    test_probabilities.append(confidence)\\n",
    "\\n",
    "# Calculate metrics\\n",
    "accuracy = accuracy_score(y_test, test_predictions)\\n",
    "report = classification_report(y_test, test_predictions)\\n",
    "\\n",
    "print(f\\"Test Accuracy: {accuracy:.3f}\\")\\n",
    "print(\\"\\\\nClassification Report:\\")\\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\\n",
    "cm = confusion_matrix(y_test, test_predictions, labels=['review', 'approve'])\\n",
    "\\n",
    "plt.figure(figsize=(8, 6))\\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n",
    "            xticklabels=['Review', 'Approve'], \\n",
    "            yticklabels=['Review', 'Approve'])\\n",
    "plt.title('Confusion Matrix')\\n",
    "plt.ylabel('True Label')\\n",
    "plt.xlabel('Predicted Label')\\n",
    "plt.show()\\n",
    "\\n",
    "# Feature importance analysis\\n",
    "if hasattr(classifier.model, 'feature_importances_'):\\n",
    "    feature_importance = pd.DataFrame({\\n",
    "        'feature': list(X_train[0].keys()),\\n",
    "        'importance': classifier.model.feature_importances_\\n",
    "    }).sort_values('importance', ascending=False)\\n",
    "    \\n",
    "    plt.figure(figsize=(10, 6))\\n",
    "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\\n",
    "    plt.title('Top 10 Most Important Features')\\n",
    "    plt.xlabel('Feature Importance')\\n",
    "    plt.tight_layout()\\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test with Sample Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some sample claims\\n",
    "sample_claims = [\\n",
    "    {\\n",
    "        'name': 'John Doe',\\n",
    "        'date': '2024-01-15',\\n",
    "        'diagnosis': 'Fractured arm',\\n",
    "        'amount': '3200.00',\\n",
    "        'provider': 'Dr. Smith',\\n",
    "        'policy_number': 'POL-12345'\\n",
    "    },\\n",
    "    {\\n",
    "        'name': 'Jane Smith',\\n",
    "        'date': '2024-01-14',\\n",
    "        'diagnosis': 'Routine checkup',\\n",
    "        'amount': '150.00',\\n",
    "        'provider': 'Medical Center',\\n",
    "        'policy_number': 'POL-67890'\\n",
    "    },\\n",
    "    {\\n",
    "        'name': 'Bob Johnson',\\n",
    "        'date': '2024-01-13',\\n",
    "        'diagnosis': 'Heart surgery',\\n",
    "        'amount': '25000.00',\\n",
    "        'provider': 'City Hospital',\\n",
    "        'policy_number': 'POL-11111'\\n",
    "    }\\n",
    "]\\n",
    "\\n",
    "print(\\"Testing model with sample claims:\\")\\n",
    "print(\\"=\\" * 50)\\n",
    "\\n",
    "for i, claim in enumerate(sample_claims, 1):\\n",
    "    result = classifier.classify_claim(claim)\\n",
    "    \\n",
    "    print(f\\"\\\\nClaim {i}:\\")\\n",
    "    print(f\\"  Patient: {claim['name']}\\")\\n",
    "    print(f\\"  Diagnosis: {claim['diagnosis']}\\")\\n",
    "    print(f\\"  Amount: ${claim['amount']}\\")\\n",
    "    print(f\\"  Prediction: {result['prediction']}\\")\\n",
    "    print(f\\"  Confidence: {result['confidence']}%\\")\\n",
    "    print(f\\"  Risk Score: {result['risk_score']}%\\")\\n",
    "    print(f\\"  Recommended Action: {result['recommended_action']}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Training Data for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data for future reference\\n",
    "training_df = pd.DataFrame({\\n",
    "    'features': features_list,\\n",
    "    'label': labels\\n",
    "})\\n",
    "\\n",
    "training_df.to_csv('../data/training_data.csv', index=False)\\n",
    "print(\\"Training data saved to ../data/training_data.csv\\")\\n",
    "\\n",
    "# Save sample claims for testing\\n",
    "sample_df = pd.DataFrame(sample_claims)\\n",
    "sample_df.to_csv('../data/sample_claims.csv', index=False)\\n",
    "print(\\"Sample claims saved to ../data/sample_claims.csv\\")\\n",
    "\\n",
    "print(\\"\\\\nModel training and evaluation completed successfully!\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
